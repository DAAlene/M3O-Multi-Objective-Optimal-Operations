
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Multi-Objective Optimal Operation (M3O) Toolbox</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-05-25"><meta name="DC.source" content="main_script_demo.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Multi-Objective Optimal Operation (M3O) Toolbox</h1><!--introduction--><p>M3O is a Matlab toolbox for designing the optimal operations of multipurpose water reservoir systems. M3O allows users to design Pareto optimal (or approximate) operating policies for managing water reservoir systems through several alternative state-of-the-art methods. Version 1.0 of M3O includes Deterministic and Stochastic Dynamic Programming, Implicit Stochastic Optimization, Sampling Stochastic Dynamic Programming, fitted Q-iteration, Evolutionary Multi-Objective Direct Policy Search, and Model Predictive Control. The toolbox is designed to be accessible to practitioners, researchers, and students, and to provide a fully commented and customizable code for more experienced users.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Configure general system parameters</a></li><li><a href="#7">Run DDP - Deterministic Dynamic Programming</a></li><li><a href="#11">Run SDP - Stochastic Dynamic Programming</a></li><li><a href="#15">Run EMODPS - Evolutionary Multi-Objective Direct Policy Search)</a></li><li><a href="#18">Run FQI - Fitted Q-Iteration</a></li><li><a href="#22">Run MPC - Model Predictive Control</a></li><li><a href="#25">Run ISO - Implicit Stochastic Optimization</a></li><li><a href="#28">Run SSDP - Sampling Stochastic Dynamic Programming</a></li></ul></div><pre class="codeinput">clear <span class="string">all</span>;
clc

addpath(genpath(<span class="string">'sim'</span>))
addpath(genpath(<span class="string">'lib'</span>))
</pre><h2>Configure general system parameters<a name="2"></a></h2><p>This section is specific to the case study at hand. The structure sys_param is shared by the inner function of the toolbox via the global command.</p><pre class="codeinput"><span class="keyword">global</span> sys_param;
</pre><p>As an example, we provide the modeling of Lake Como, that is a regulated lake in Northern Italy (Figure 1, left panel) fed by a 3,500 <img src="main_script_demo_eq16611302842301964662.png" alt="$\mathrm{km}^2$"> catchment, where the lake inflow and effluent is the Adda River, which supports several agricultural districts with a total surface of 1,400 <img src="main_script_demo_eq16611302842301964662.png" alt="$\mathrm{km}^2$">. Major crops are cereals, especially maize, along with temporary grasslands for livestocks. Beside water supply, the regulation of the lake, which has an active storage capacity of 254 <img src="main_script_demo_eq11528782790331759598.png" alt="$\mathrm{Mm}^3$"> aims also to prevent flooding along the lake shores, particularly in Como city, which is the lowest point of the shoreline. In particular, the release decision provided by the operating policy is constrained within the regulation range shown in Figure 1 (right panel) by some physical and normative constraints that force the operator to completely close the dam if the level is below -0.5 m and, viceversa, to completely open the dam if the level is above 1.25 m. The corresponding parameters are:</p><pre class="codeinput">sys_param.simulation.h0    =      -0.5;  <span class="comment">% lowest water level [cm]</span>
sys_param.simulation.A     = 145900000;  <span class="comment">% surface of the lake [cm2]</span>
sys_param.simulation.r_min =         0;  <span class="comment">% minimum possible release [m3/s]</span>
sys_param.simulation.r_max =       518;  <span class="comment">% maximum possible release [m3/s]</span>
</pre><p><img vspace="5" hspace="5" src="Figure01.png" alt=""> </p><p>Figure 1: Map of the Lake Como system (left panel) and illustration of the associated zone of operation discreption delimited by the physical/normative constraints on the maximum and minimum release (right panel).</p><p>The competing interests of irrigation supply and flood control can be modeled using the following formulations:</p><div><ul><li>Flooding: the daily average level excess with respect to the flooding   threshold, <img src="main_script_demo_eq06537256527460945224.png" alt="$\bar{h}$"> = 0.8 m, i.e.:</li></ul></div><p><img src="main_script_demo_eq11885085180668470435.png" alt="$$J^{flood} = \frac{1}{H} \sum_{t=1}^H \max \left( \left( h_t - \bar{h} \right), 0 \right)$$"></p><pre class="codeinput">sys_param.simulation.hFLO = 0.8 ;  <span class="comment">% flooding threshold [m]</span>
</pre><div><ul><li>Irrigation: the daily average water deficit is taken w.r.t. the downstream   demand <img src="main_script_demo_eq00125694759345388081.png" alt="$w$"> = 370 <img src="main_script_demo_eq11703343379119444164.png" alt="$m^3/s$">, i.e:</li></ul></div><p><img src="main_script_demo_eq07697621685744671729.png" alt="$$J^{irr} = \frac{1}{H} \sum_{t=1}^H \max \left( \left( w - r_{t+1} \right), 0 \right)$$"></p><pre class="codeinput">sys_param.simulation.w = 370 ;  <span class="comment">% water demand [m3/s]</span>
</pre><p>Note that to simplify the solution of the problem, we assume the system as stationary (i.e., we remove the seasonality) and adapted the values of inflows, water demand, and flooding threshold to maintain the real conflicts between water supply and flood protection. The simulation step is one day long and the initial level of the lake is set to <img src="main_script_demo_eq04851902034671085909.png" alt="$0.6\ m$">.</p><pre class="codeinput">sys_param.simulation.h_in  =                         0.6;  <span class="comment">% water level of the first day [m]</span>
sys_param.simulation.delta =                    60*60*24;  <span class="comment">% timestep length [s]</span>
sys_param.simulation.q     = load(<span class="string">'inflow.txt'</span>,<span class="string">'-ascii'</span>); <span class="comment">% synthesis inflow sample assuming same pdf for each calendar day</span>

[sys_param.simulation.vv, sys_param.simulation.VV] = deal(0);
</pre><h2>Run DDP - Deterministic Dynamic Programming<a name="7"></a></h2><p>Deterministic dynamic programming (DDP) formulate the operating policy design problem as a sequential decision-making process. It requires a discretization of the values of storage, decision and inflow:</p><pre class="codeinput">clc
addpath(<span class="string">'./DP'</span>)

load <span class="string">'grids.mat'</span>;
sys_param.algorithm = grids;
sys_param.algorithm.name = <span class="string">'ddp'</span>;
sys_param.algorithm.Hend = 0 ; <span class="comment">% penalty for last state set to 0</span>
</pre><p>For each discretized couple of values of state and inflow, it is possible to compute the daily minimum/maximum release offline:</p><pre class="codeinput">[vv, VV] = construct_rel_matrices(grids);
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;
</pre><p>DDP is a single objective method so weights are needed to aggregate the objectives values. By changing weights it is possible to explore the Pareto Front.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_ddp = nan(Nalt,2);
Hddp   = cell(Nalt,1);
</pre><p>For each weight combination we run the algorithm and store the resulting performance as well as the Bellman function for reuse.</p><pre class="codeinput"><span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_ddp(i,:), Hddp{i}] = run_ddp() ;
<span class="keyword">end</span>

figure; plot( JJ_ddp(:,1), JJ_ddp(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><img vspace="5" hspace="5" src="main_script_demo_01.png" alt=""> <h2>Run SDP - Stochastic Dynamic Programming<a name="11"></a></h2><p>Stochastic dynamic programming (SDP) formulate the operating policy design problem as a sequential decision-making process under the stochastic disturbance. The discretization of the values of storage, decision and inflow is similar to the DDP. Notice that in this example we assume the full stationarity, therefore for each decision stage the Bellman value function is essentially the same.</p><pre class="codeinput">clc
addpath(<span class="string">'./SDP'</span>)

load <span class="string">'grids.mat'</span>;
sys_param.algorithm = grids;
sys_param.algorithm.name = <span class="string">'sdp'</span>;
sys_param.algorithm.Hend = 0 ; <span class="comment">% penalty set to 0</span>
sys_param.algorithm.T = 1 ;    <span class="comment">% the period is equal 1 as we assume stationary conditions</span>
sys_param.algorithm.gamma = 1; <span class="comment">% set future discount factor</span>
</pre><p>As for DDP, it is possible to compute the daily minimum/maximum release offline:</p><pre class="codeinput">[vv, VV] = construct_rel_matrices(grids);
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;
</pre><p>A major difference w.r.t. DDP is that the disturbance stochasticity is  modeled as a certain probability density function. In this case the inflow is assumed to be distributed as a log normal and the parameters are fitted on the data available.</p><pre class="codeinput">sys_param.algorithm.q_stat = lognfit(sys_param.simulation.q);
</pre><p>SDP is also a single objective method so we explore the Pareto Front by changing weights.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_sdp = nan(Nalt,2);
Hsdp   = cell(Nalt, 1);

<span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_sdp(i,:), Hsdp{i}] = run_sdp();
<span class="keyword">end</span>

figure; plot( JJ_sdp(:,1), JJ_sdp(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><img vspace="5" hspace="5" src="main_script_demo_02.png" alt=""> <h2>Run EMODPS - Evolutionary Multi-Objective Direct Policy Search)<a name="15"></a></h2><p>Evolutionary multi-objective direct policy search (EMODPS) is a simulation-based approach that combines direct policy search, non-linear approximating networks, and multi-objective evolutionary algorithms. Specifically, the optimal control policy can be assumed of a particular function, e.g., piece-wise linear, parameterized by a set of parameters, where the value of parameters can be optimized via simulation based global optimization algorithm. Notice that EMODPS being a fully multi-objective algorithm does not require the aggregation of objectives into a single measure.</p><pre class="codeinput">clc
addpath(<span class="string">'./EMODPS'</span>)
</pre><p>Define the parameterized class for the policy (i.e., standard operating policy), in this case we assume the standard piece-wise linear function to parameterize the control policy, and we use NSGAII to optimize the parameters that best capture the multi-objective Pareto Front.</p><pre class="codeinput">sys_param.algorithm.name = <span class="string">'emodps'</span> ;
pClass = <span class="string">'stdOP'</span>;
</pre><p>Define MOEA and its setting (i.e., NSGAII)</p><pre class="codeinput">moea_param.name = <span class="string">'NSGAII'</span>;
moea_param.pop  = 40; <span class="comment">% number of individuals; requires fine tuning</span>
moea_param.gen  = 50; <span class="comment">% number of generation; requires fine tuning</span>

[JJ_emodps, Popt] = run_emodps(pClass, moea_param) ;

figure; plot( JJ_emodps(:,1), JJ_emodps(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><img vspace="5" hspace="5" src="main_script_demo_03.png" alt=""> <h2>Run FQI - Fitted Q-Iteration<a name="18"></a></h2><p>Fitted Q-Iteration (FQI) is a batch-mode reinforcement learning (RL) algorithm that combines RL concepts of off-line learning and functional approximation of the value function.</p><pre class="codeinput">clc
addpath(<span class="string">'./FQI'</span>)

load <span class="string">'grids.mat'</span>;
sys_param.algorithm = grids;
</pre><p>FQI starts with collection of the results from a number of Monte Carlo simulations, from which FQI will subsequently learn the best value function.</p><pre class="codeinput">sys_param.algorithm.name = <span class="string">'doe'</span>;
[F, G] = run_doe(50) ; <span class="comment">% create 50 samples of tuples</span>
</pre><p>Similar, FQI is a single objective method so weights are needed to aggregate the objectives values. By changing weights it is possible to explore the Pareto Front.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_fqi = nan(Nalt, 2);
Qfqi   = cell(Nalt, 1);
</pre><p>Regression techniques are used to approximate the actual value function. In this case, we use tree-based regressors (i.e. extra-trees).</p><pre class="codeinput">reg_param.name    = <span class="string">'ET'</span>;
reg_param.M       = 200;  <span class="comment">% number of trees</span>
reg_param.nmin    = 25;   <span class="comment">% minimum number of points per leaf</span>
reg_param.maxIter = 40;

sys_param.algorithm.name = <span class="string">'fqi'</span>;
sys_param.algorithm.gamma = 0.99;

<span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_fqi(i,:), Qfqi{i}] = run_fqi(F, G, reg_param);
<span class="keyword">end</span>

figure; plot( JJ_fqi(:,1), JJ_fqi(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><pre class="codeoutput error">Undefined function or variable 'Nu'.

Error in readQ (line 40)
for i = 1: Nu

Error in run_fqi (line 97)
    H  = readQ(x1, discr_s, discr_u, Q_curr);

Error in main_script_demo (line 263)
  [JJ_fqi(i,:), Qfqi{i}] = run_fqi(F, G, reg_param);
</pre><h2>Run MPC - Model Predictive Control<a name="22"></a></h2><p>Model Predictive Control is a real-time control approach based on the sequential resolution of multiple open-loop control problems defined over a finite, receding time horizon.</p><pre class="codeinput">clc;
addpath(<span class="string">'./MPC'</span>)

sys_param.algorithm.name    = <span class="string">'mpc'</span>;
</pre><p>At each time step, a forecast of the inflow, called nominal value, is provided over the finite future horizon [t, t + P].</p><pre class="codeinput">sys_param.algorithm.P       = 3;   <span class="comment">% Length of the moving prediction horizon</span>
sys_param.algorithm.mi_e    = mean(sys_param.simulation.q);
sys_param.algorithm.sigma_e = std(sys_param.simulation.q);
</pre><p>MPC works for a single objective method so we explore the Pareto Front by changing weights.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_mpc = nan(Nalt, 2);
Ompc   = cell(Nalt, 1);

errorLevel = 0; <span class="comment">% Disturbance prediction error [%]</span>

<span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_mpc(i,:), Ompc{i}] = run_mpc(errorLevel);
<span class="keyword">end</span>

figure; plot( JJ_mpc(:,1), JJ_mpc(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><h2>Run ISO - Implicit Stochastic Optimization<a name="25"></a></h2><p>The Implicit Stochastic Optimization (ISO) design the operating policy by regressing the predictors (e.g., state variables) towards the predictands (decision variables). To collect the samples for building the regression models, ISO methods relies on a set of deterministic optimizations (e.g., DDP) before hand.</p><pre class="codeinput">clc;
addpath(<span class="string">'./DP'</span>)

load <span class="string">'grids.mat'</span>;
sys_param.algorithm = grids;
sys_param.algorithm.name = <span class="string">'iso'</span>;

[vv, VV] = construct_rel_matrices(grids); <span class="comment">% compute daily minimum/maximum release matrixes</span>
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;
sys_param.algorithm.Hend    = 0 ; <span class="comment">% penalty set to 0</span>
</pre><p>Define regression method to define a function mapping the selecte variables into release decisions.</p><pre class="codeinput">regressor = <span class="string">'linear_spline'</span>;
sys_param.algorithm.regressorName = regressor;
</pre><p>ISO also works for a single objective method so we explore the Pareto Front by changing weights.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt = size(lambda,1);

[JJ_iso, err_perc] = deal(nan(Nalt,2));
policy = cell(Nalt,1);

<span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_iso(i,:), policy{i}, err_perc(i,:)] = run_iso(regressor);
<span class="keyword">end</span>

figure; plot( JJ_iso(:,1), JJ_iso(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><h2>Run SSDP - Sampling Stochastic Dynamic Programming<a name="28"></a></h2><p>Sampling Stochastic Dynamic Programming (SSDP) replaces the explicit probability description of the system disturbances in SDP with the use of multiple scenarios as an empirical distribution. These scenarios can be either multiple historical time-series or ensemble forecast, with latter providing more accurate information about the future conditions.</p><pre class="codeinput">clc;
addpath(<span class="string">'./SSDP'</span>)

load <span class="string">'grids.mat'</span>;
sys_param.algorithm = grids;
sys_param.algorithm.name = <span class="string">'ssdp'</span>;
sys_param.algorithm.Hend = 0 ; <span class="comment">% penalty set to 0</span>

[vv, VV] = construct_rel_matrices(grids); <span class="comment">% compute daily minimum/maximum release matrixes</span>
sys_param.algorithm.min_rel    = vv;
sys_param.algorithm.max_rel    = VV;
sys_param.algorithm.T          = 365;
sys_param.algorithm.interp_foo = @interp1qr; <span class="comment">% default linear interpolator</span>
sys_param.algorithm.gamma      = 1;
sys_param.algorithm.Pr_mode    = 2;
sys_param.algorithm.cycle_T    = 300;
sys_param.algorithm.forecast_T = 60;
</pre><p>As for SDP, in SSDP the disturbance is assumed to be distributed as a log normal and the parameters are fitted on the data available. The model is then used to create the test samples for a total of 25 ensembles with 365 days each.</p><pre class="codeinput">q_stat = lognfit(sys_param.simulation.q) ;
esp_sample = lognrnd( q_stat(1), q_stat(2), 365, 25 );
sys_param.algorithm.esp_sample = esp_sample ;
</pre><p>SSDP works for a single objective method so we explore the Pareto Front by changing weights.</p><pre class="codeinput">lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9; 0 1];
Nalt = size(lambda,1);

JJ_ssdp  = nan(Nalt, 2);
H_policy = cell(Nalt, 1);

<span class="keyword">for</span> i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_ssdp(i,:), H_policy{i}] = run_ssdp() ;
<span class="keyword">end</span>

figure; plot( JJ_ssdp(:,1), JJ_ssdp(:,2), <span class="string">'o'</span> );
xlabel(<span class="string">'flooding'</span>); ylabel(<span class="string">'irrigation'</span>);
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Multi-Objective Optimal Operation (M3O) Toolbox
%
% M3O is a Matlab toolbox for designing the optimal operations of multipurpose 
% water reservoir systems. M3O allows users to design Pareto optimal (or 
% approximate) operating policies for managing water reservoir systems through 
% several alternative state-of-the-art methods. Version 1.0 of M3O includes 
% Deterministic and Stochastic Dynamic Programming, Implicit Stochastic 
% Optimization, Sampling Stochastic Dynamic Programming, fitted Q-iteration, 
% Evolutionary Multi-Objective Direct Policy Search, and Model Predictive Control. 
% The toolbox is designed to be accessible to practitioners, researchers, and 
% students, and to provide a fully commented and customizable code for more 
% experienced users.


%%
clear all;
clc

addpath(genpath('sim'))
addpath(genpath('lib'))

%% Configure general system parameters
% This section is specific to the case study at hand. The structure sys_param 
% is shared by the inner function of the toolbox via the global command.

global sys_param;

%%% 
% As an example, we provide the modeling of Lake Como, that is a regulated
% lake in Northern Italy (Figure 1, left panel) fed by a 3,500 $\mathrm{km}^2$
% catchment, where the lake inflow and effluent is the Adda River, which
% supports several agricultural districts with a total surface of 1,400
% $\mathrm{km}^2$. Major crops are cereals, especially maize, along with temporary
% grasslands for livestocks. Beside water supply, the regulation of the
% lake, which has an active storage capacity of 254 $\mathrm{Mm}^3$ aims also to
% prevent flooding along the lake shores, particularly in Como city, which
% is the lowest point of the shoreline. In particular, the release decision
% provided by the operating policy is constrained within the regulation
% range shown in Figure 1 (right panel) by some physical and normative
% constraints that force the operator to completely close the dam if the
% level is below -0.5 m and, viceversa, to completely open the dam if the
% level is above 1.25 m. The corresponding parameters
% are:

sys_param.simulation.h0    =      -0.5;  % lowest water level [cm]
sys_param.simulation.A     = 145900000;  % surface of the lake [cm2]
sys_param.simulation.r_min =         0;  % minimum possible release [m3/s]
sys_param.simulation.r_max =       518;  % maximum possible release [m3/s]


%%%
% <<Figure01.png>>
%
% Figure 1: Map of the Lake Como system (left panel) and illustration of the
% associated zone of operation discreption delimited by the physical/normative 
% constraints on the maximum and minimum release (right panel).
%
%
% The competing interests of irrigation supply and flood control can be modeled
% using the following formulations:
%
% * Flooding: the daily average level excess with respect to the flooding 
%   threshold, $\bar{h}$ = 0.8 m, i.e.:
%
% $$J^{flood} = \frac{1}{H} \sum_{t=1}^H \max \left( \left( h_t - \bar{h} \right), 0 \right)$$
%

sys_param.simulation.hFLO = 0.8 ;  % flooding threshold [m]

%%%
% * Irrigation: the daily average water deficit is taken w.r.t. the downstream
%   demand $w$ = 370 $m^3/s$, i.e:
%
% $$J^{irr} = \frac{1}{H} \sum_{t=1}^H \max \left( \left( w - r_{t+1} \right), 0 \right)$$
%

sys_param.simulation.w = 370 ;  % water demand [m3/s]

%%% 
% Note that to simplify the solution of the problem, we assume the system
% as stationary (i.e., we remove the seasonality) and adapted the values of 
% inflows, water demand, and flooding threshold to maintain the real conflicts
% between water supply and flood protection. The simulation step is one day
% long and the initial level of the lake is set to $0.6\ m$.

sys_param.simulation.h_in  =                         0.6;  % water level of the first day [m]
sys_param.simulation.delta =                    60*60*24;  % timestep length [s]
sys_param.simulation.q     = load('inflow.txt','-ascii'); % synthesis inflow sample assuming same pdf for each calendar day

[sys_param.simulation.vv, sys_param.simulation.VV] = deal(0); 

%% Run DDP - Deterministic Dynamic Programming
% Deterministic dynamic programming (DDP) formulate the operating policy
% design problem as a sequential decision-making process. It requires a
% discretization of the values of storage, decision and inflow:
clc
addpath('./DP')

load 'grids.mat';
sys_param.algorithm = grids;
sys_param.algorithm.name = 'ddp';
sys_param.algorithm.Hend = 0 ; % penalty for last state set to 0

%%%
% For each discretized couple of values of state and inflow, it is possible
% to compute the daily minimum/maximum release offline:

[vv, VV] = construct_rel_matrices(grids);
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;

%%%
% DDP is a single objective method so weights are needed to aggregate the 
% objectives values. By changing weights it is possible to explore the
% Pareto Front.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_ddp = nan(Nalt,2);
Hddp   = cell(Nalt,1);

%%%
% For each weight combination we run the algorithm and store the resulting
% performance as well as the Bellman function for reuse.

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_ddp(i,:), Hddp{i}] = run_ddp() ;
end

figure; plot( JJ_ddp(:,1), JJ_ddp(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');

%% Run SDP - Stochastic Dynamic Programming
% Stochastic dynamic programming (SDP) formulate the operating policy
% design problem as a sequential decision-making process under the
% stochastic disturbance. The discretization of the values of storage,
% decision and inflow is similar to the DDP. Notice that in this 
% example we assume the full stationarity, therefore for each decision stage
% the Bellman value function is essentially the same.

clc
addpath('./SDP')

load 'grids.mat';
sys_param.algorithm = grids;
sys_param.algorithm.name = 'sdp';
sys_param.algorithm.Hend = 0 ; % penalty set to 0
sys_param.algorithm.T = 1 ;    % the period is equal 1 as we assume stationary conditions
sys_param.algorithm.gamma = 1; % set future discount factor

%%%
% As for DDP, it is possible to compute the daily minimum/maximum release 
% offline:

[vv, VV] = construct_rel_matrices(grids);
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;

%%%
% A major difference w.r.t. DDP is that the disturbance stochasticity is 
%  modeled as a certain probability density function. In this case the inflow
% is assumed to be distributed as a log normal and the parameters are fitted on
% the data available.

sys_param.algorithm.q_stat = lognfit(sys_param.simulation.q);

%%%
% SDP is also a single objective method so we explore the Pareto Front by 
% changing weights.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_sdp = nan(Nalt,2);
Hsdp   = cell(Nalt, 1);

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_sdp(i,:), Hsdp{i}] = run_sdp();
end

figure; plot( JJ_sdp(:,1), JJ_sdp(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');

%% Run EMODPS - Evolutionary Multi-Objective Direct Policy Search)
% Evolutionary multi-objective direct policy search (EMODPS) is a
% simulation-based approach that combines direct policy search, non-linear
% approximating networks, and multi-objective evolutionary algorithms.
% Specifically, the optimal control policy can be assumed of a particular
% function, e.g., piece-wise linear, parameterized by a set of parameters,
% where the value of parameters can be optimized via simulation based
% global optimization algorithm. Notice that EMODPS being a fully
% multi-objective algorithm does not require the aggregation of objectives
% into a single measure.

clc
addpath('./EMODPS')

%%%
% Define the parameterized class for the policy (i.e., standard operating
% policy), in this case we assume the standard piece-wise linear function
% to parameterize the control policy, and we use NSGAII to optimize the
% parameters that best capture the multi-objective Pareto Front.

sys_param.algorithm.name = 'emodps' ;
pClass = 'stdOP'; 

%%%
% Define MOEA and its setting (i.e., NSGAII)

moea_param.name = 'NSGAII';
moea_param.pop  = 40; % number of individuals; requires fine tuning
moea_param.gen  = 50; % number of generation; requires fine tuning

[JJ_emodps, Popt] = run_emodps(pClass, moea_param) ;

figure; plot( JJ_emodps(:,1), JJ_emodps(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');

%% Run FQI - Fitted Q-Iteration
% Fitted Q-Iteration (FQI) is a batch-mode reinforcement learning (RL)
% algorithm that combines RL concepts of off-line learning and functional
% approximation of the value function.

clc
addpath('./FQI')

load 'grids.mat';
sys_param.algorithm = grids;

%%%
% FQI starts with collection of the results from a number of Monte Carlo
% simulations, from which FQI will subsequently learn the best value
% function.

sys_param.algorithm.name = 'doe';
[F, G] = run_doe(50) ; % create 50 samples of tuples 

%%%
% Similar, FQI is a single objective method so weights are needed to
% aggregate the objectives values. By changing weights it is possible to
% explore the Pareto Front.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_fqi = nan(Nalt, 2);
Qfqi   = cell(Nalt, 1);

%%%
% Regression techniques are used to approximate the actual value function. 
% In this case, we use tree-based regressors (i.e. extra-trees). 

reg_param.name    = 'ET';
reg_param.M       = 200;  % number of trees
reg_param.nmin    = 25;   % minimum number of points per leaf
reg_param.maxIter = 40;

sys_param.algorithm.name = 'fqi';
sys_param.algorithm.gamma = 0.99;

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_fqi(i,:), Qfqi{i}] = run_fqi(F, G, reg_param);
end

figure; plot( JJ_fqi(:,1), JJ_fqi(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');


%% Run MPC - Model Predictive Control
% Model Predictive Control is a real-time control approach based on the 
% sequential resolution of multiple open-loop control problems defined over a 
% finite, receding time horizon.

clc;
addpath('./MPC')

sys_param.algorithm.name    = 'mpc';

%%%
% At each time step, a forecast of the inflow, called nominal value, is 
% provided over the finite future horizon [t, t + P]. 

sys_param.algorithm.P       = 3;   % Length of the moving prediction horizon
sys_param.algorithm.mi_e    = mean(sys_param.simulation.q);
sys_param.algorithm.sigma_e = std(sys_param.simulation.q);

%%%
% MPC works for a single objective method so we explore the Pareto Front by 
% changing weights.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt   = size(lambda,1);
JJ_mpc = nan(Nalt, 2);
Ompc   = cell(Nalt, 1);

errorLevel = 0; % Disturbance prediction error [%]

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_mpc(i,:), Ompc{i}] = run_mpc(errorLevel);
end

figure; plot( JJ_mpc(:,1), JJ_mpc(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');


%% Run ISO - Implicit Stochastic Optimization
% The Implicit Stochastic Optimization (ISO) design the operating policy by
% regressing the predictors (e.g., state variables) towards the predictands
% (decision variables). To collect the samples for building the regression
% models, ISO methods relies on a set of deterministic optimizations (e.g.,
% DDP) before hand.

clc;
addpath('./DP')

load 'grids.mat';
sys_param.algorithm = grids;
sys_param.algorithm.name = 'iso';

[vv, VV] = construct_rel_matrices(grids); % compute daily minimum/maximum release matrixes
sys_param.algorithm.min_rel = vv;
sys_param.algorithm.max_rel = VV;
sys_param.algorithm.Hend    = 0 ; % penalty set to 0

%%%
% Define regression method to define a function mapping the selecte variables
% into release decisions.

regressor = 'linear_spline';
sys_param.algorithm.regressorName = regressor;

%%%
% ISO also works for a single objective method so we explore the Pareto Front
% by changing weights.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9;  0 1];
Nalt = size(lambda,1);

[JJ_iso, err_perc] = deal(nan(Nalt,2));
policy = cell(Nalt,1);

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_iso(i,:), policy{i}, err_perc(i,:)] = run_iso(regressor);
end

figure; plot( JJ_iso(:,1), JJ_iso(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');

%% Run SSDP - Sampling Stochastic Dynamic Programming
% Sampling Stochastic Dynamic Programming (SSDP) replaces the explicit
% probability description of the system disturbances in SDP with the use of
% multiple scenarios as an empirical distribution. These scenarios can be
% either multiple historical time-series or ensemble forecast, with latter
% providing more accurate information about the future conditions. 

clc;
addpath('./SSDP')

load 'grids.mat';
sys_param.algorithm = grids;
sys_param.algorithm.name = 'ssdp';
sys_param.algorithm.Hend = 0 ; % penalty set to 0

[vv, VV] = construct_rel_matrices(grids); % compute daily minimum/maximum release matrixes
sys_param.algorithm.min_rel    = vv;
sys_param.algorithm.max_rel    = VV;
sys_param.algorithm.T          = 365;
sys_param.algorithm.interp_foo = @interp1qr; % default linear interpolator 
sys_param.algorithm.gamma      = 1;
sys_param.algorithm.Pr_mode    = 2; 
sys_param.algorithm.cycle_T    = 300;
sys_param.algorithm.forecast_T = 60;

%%%
% As for SDP, in SSDP the disturbance is assumed to be distributed as a log
% normal and the parameters are fitted on the data available. The model is then
% used to create the test samples for a total of 25 ensembles with 365 days 
% each.

q_stat = lognfit(sys_param.simulation.q) ;
esp_sample = lognrnd( q_stat(1), q_stat(2), 365, 25 );
sys_param.algorithm.esp_sample = esp_sample ;

%%%
% SSDP works for a single objective method so we explore the Pareto Front by 
% changing weights.

lambda = [1 0; .75 .25; .5 .5 ; .35 .65; .2 .8; .1 .9; 0 1];
Nalt = size(lambda,1);

JJ_ssdp  = nan(Nalt, 2);
H_policy = cell(Nalt, 1);

for i = 1: Nalt
  sys_param.algorithm.weights = lambda(i,:);
  [JJ_ssdp(i,:), H_policy{i}] = run_ssdp() ;
end

figure; plot( JJ_ssdp(:,1), JJ_ssdp(:,2), 'o' );
xlabel('flooding'); ylabel('irrigation');

##### SOURCE END #####
--></body></html>